{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpath = '../Data/X/'\n",
    "weather_df = pd.read_csv(Xpath + \"hourly_weather_newark.csv\")\n",
    "weather_df[\"Date\"] = pd.to_datetime(weather_df[\"Date\"])\n",
    "weather_df[\"Date\"] = weather_df[\"Date\"].dt.round('h')\n",
    "\n",
    "import os\n",
    "\n",
    "Ypath = \"../Data/Y/\"\n",
    "\n",
    "files = os.listdir(Ypath)\n",
    "\n",
    "rate_classes = {}\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(Ypath + file)\n",
    "    name = file.removesuffix(\"_cleaned.csv\")\n",
    "\n",
    "    rate_classes[name] = df\n",
    "    \n",
    "    df.rename(columns={name: \"Load\"}, inplace=True)\n",
    "    df[\"Load\"] = df[\"Load\"] / 1000 # make sure all load units are in megawatts, MW = KW/1000\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "feature_matrix = rate_classes['Res'].merge(weather_df, on='Date')\n",
    "\n",
    "# to POSIX Timestamp (number of seconds that have passed since January 1, 1970)\n",
    "#feature_matrix = feature_matrix[['Date', 'Load', 'Temperature (F)', 'Humidity (%)']]\n",
    "feature_matrix['Date'] = feature_matrix['Date'].apply(lambda t: int(t.timestamp()))\n",
    "\n",
    "# Scale the load so that the values are closer to the temperature values\n",
    "feature_matrix['Load'] = feature_matrix['Load'] * (feature_matrix['Temperature (F)'].mean() / feature_matrix['Load'].mean())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scale_columns = ['Load', 'Temperature (F)', 'Humidity (%)']\n",
    "feature_matrix[scale_columns] = scaler.fit_transform(feature_matrix[scale_columns])\n",
    "print(feature_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12  # Adjust this as needed\n",
    "X = []\n",
    "y = []\n",
    "target_dates = feature_matrix['Date'][window_size:].reset_index(drop=True)  # Ensure proper indexing\n",
    "\n",
    "# Loop to create sequences of data\n",
    "for i in range(window_size, len(feature_matrix)):\n",
    "    X.append(feature_matrix.iloc[i - window_size:i][['Load', 'Temperature (F)', 'Humidity (%)']].values)\n",
    "    y.append(feature_matrix.iloc[i][['Load']].values)  # Predict the 'Load'\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Train-test split (without shuffling)\n",
    "X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(\n",
    "    X, y, target_dates, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Reshaping X_train and X_test for LSTM (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n",
    "\n",
    "y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bdb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1],  X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "# Create a dummy array of shape (n_samples, 3) with predictions in the first column\n",
    "predictions_with_dummy = np.zeros((predictions.shape[0], 3))\n",
    "predictions_with_dummy[:, 0] = predictions.flatten()  # Fill only the first column with predictions\n",
    "\n",
    "# Now inverse scale the predictions\n",
    "predictions_rescaled = scaler.inverse_transform(predictions_with_dummy)[:, 0]  # Take only the first column (Load)\n",
    "\n",
    "# Rescale y_test as well\n",
    "y_test_rescaled = scaler.inverse_transform(np.hstack((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], 2)))))[:, 0]  # Fill with dummy columns\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(np.mean((y_test_rescaled - predictions_rescaled)**2))\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Train vs Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_rescaled, label='Actual Res_cleaned (Load)', marker='o')\n",
    "plt.plot(predictions_rescaled, label='Predicted Load', marker='x')\n",
    "plt.title('Actual vs Predicted Load')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load (MW)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
